{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "invariant-risk-minimization-colored-mnist.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8f9edac603a84c60993b2cdc8c8a2fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b7be1a56cd99483cb1116fb032949e45",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_303f4ce7d1d442179945e946a72595ca",
              "IPY_MODEL_5ae0ac86752049f08f5a33f94aacaf01"
            ]
          }
        },
        "b7be1a56cd99483cb1116fb032949e45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "303f4ce7d1d442179945e946a72595ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_1b4f8eae681f4b17bd08745f04861bba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.53MB of 0.53MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43314268dcf742dfb653d3ea1627a66a"
          }
        },
        "5ae0ac86752049f08f5a33f94aacaf01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_613349fa88464589aab0e60082c225bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bda3a6513e7b49919333b08a766a3e4d"
          }
        },
        "1b4f8eae681f4b17bd08745f04861bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43314268dcf742dfb653d3ea1627a66a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "613349fa88464589aab0e60082c225bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bda3a6513e7b49919333b08a766a3e4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f635414bed3b408e8c62be7b9e04b4c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eaafa163ac504739ae3d70b2e641bf9d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b5f241f79434d028a1c0d04608b6eaa",
              "IPY_MODEL_862fe77b603644f486a198767d718e50"
            ]
          }
        },
        "eaafa163ac504739ae3d70b2e641bf9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b5f241f79434d028a1c0d04608b6eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_5dca90b787ce4f1989b937c8410ba98c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.03MB of 0.03MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24924c4110834743b73030849f31c4d9"
          }
        },
        "862fe77b603644f486a198767d718e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_91036b4b4645424bb3b6b6d03182dcb3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb54edfc06814aac8dc790cde7b0135f"
          }
        },
        "5dca90b787ce4f1989b937c8410ba98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24924c4110834743b73030849f31c4d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91036b4b4645424bb3b6b6d03182dcb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb54edfc06814aac8dc790cde7b0135f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1101c46da9e1466ca29007e744596084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_527e4e7e9b744a7b83672816d1d7c22d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eeb525052d2141a590c2235ccad22a3b",
              "IPY_MODEL_4525f726dc07422185b1f1e629240266"
            ]
          }
        },
        "527e4e7e9b744a7b83672816d1d7c22d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eeb525052d2141a590c2235ccad22a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_b44fae64bf564aa6b67b2403e7fdb87b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.37MB of 0.37MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5f8d6b20fac4a34b8a11c2c8bf07e63"
          }
        },
        "4525f726dc07422185b1f1e629240266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6b770d6231aa4b50a6018765a291790d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63eabd93958a46f1b2c3b713d01d4b07"
          }
        },
        "b44fae64bf564aa6b67b2403e7fdb87b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5f8d6b20fac4a34b8a11c2c8bf07e63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6b770d6231aa4b50a6018765a291790d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63eabd93958a46f1b2c3b713d01d4b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cabf1676604493783d6804fa4aaf8ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b1ba6dfa78b24772b1952742c7cd39df",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_939f17ffa19b46f8b5eca9c061c78e03",
              "IPY_MODEL_520a2f94594a4e1da3d896e361c61740"
            ]
          }
        },
        "b1ba6dfa78b24772b1952742c7cd39df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "939f17ffa19b46f8b5eca9c061c78e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_869ab65ffc964772b4d666186b8b8863",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.62MB of 0.62MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_342ee64140624cb1b0f3cdfb864bfabb"
          }
        },
        "520a2f94594a4e1da3d896e361c61740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_227e718fec004e3b940a322d609a112b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a79f5f229f994d40ba7a29202ced4bcb"
          }
        },
        "869ab65ffc964772b4d666186b8b8863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "342ee64140624cb1b0f3cdfb864bfabb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "227e718fec004e3b940a322d609a112b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a79f5f229f994d40ba7a29202ced4bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLDC06POu-Z5"
      },
      "source": [
        "# Invariant Risk Minimization\n",
        "\n",
        "This is an attempt to reproduce the \"Colored MNIST\" experiments from the\n",
        "paper [Invariant Risk Minimization](https://arxiv.org/abs/1907.02893)\n",
        "by Arjovsky, et. al."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sopHPgEhu4Jo"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import grad\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "import torchvision.datasets.utils as dataset_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_u5rBUnvdxX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkTMK-oJveGg"
      },
      "source": [
        "## Prepare the colored MNIST dataset\n",
        "\n",
        "We define three environments (two training, one test) by randomly splitting the MNIST dataset in thirds and transforming each example as follows:\n",
        "1. Assign a binary label y to the image based on the digit: y = 0 for digits 0-4\n",
        "and y = 1 for digits 5-9.\n",
        "2. Flip the label with 25% probability.\n",
        "3. Color the image either red or green according to its (possibly flipped) label.\n",
        "4. Flip the color with a probability e that depends on the environment: 20% in\n",
        "the first training environment, 10% in the second training environment, and\n",
        "90% in the test environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knP-xNzavgAb"
      },
      "source": [
        "def color_grayscale_arr(arr, red=True):\n",
        "  \"\"\"Converts grayscale image to either red or green\"\"\"\n",
        "  assert arr.ndim == 2\n",
        "  dtype = arr.dtype\n",
        "  h, w = arr.shape\n",
        "  arr = np.reshape(arr, [h, w, 1])\n",
        "  if red:\n",
        "    arr = np.concatenate([arr,\n",
        "                          np.zeros((h, w, 2), dtype=dtype)], axis=2)\n",
        "  else:\n",
        "    arr = np.concatenate([np.zeros((h, w, 1), dtype=dtype),\n",
        "                          arr,\n",
        "                          np.zeros((h, w, 1), dtype=dtype)], axis=2)\n",
        "  return arr\n",
        "\n",
        "\n",
        "class ColoredMNIST(datasets.VisionDataset):\n",
        "  \"\"\"\n",
        "  Colored MNIST dataset for testing IRM. Prepared using procedure from https://arxiv.org/pdf/1907.02893.pdf\n",
        "\n",
        "  Args:\n",
        "    root (string): Root directory of dataset where ``ColoredMNIST/*.pt`` will exist.\n",
        "    env (string): Which environment to load. Must be 1 of 'train1', 'train2', 'test', or 'all_train'.\n",
        "    transform (callable, optional): A function/transform that  takes in an PIL image\n",
        "      and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
        "    target_transform (callable, optional): A function/transform that takes in the\n",
        "      target and transforms it.\n",
        "  \"\"\"\n",
        "  def __init__(self, root='./data', env='train1', transform=None, target_transform=None):\n",
        "    super(ColoredMNIST, self).__init__(root, transform=transform,\n",
        "                                target_transform=target_transform)\n",
        "\n",
        "    self.prepare_colored_mnist()\n",
        "    if env in ['train1', 'train2', 'test']:\n",
        "      self.data_label_tuples = torch.load(os.path.join(self.root, 'ColoredMNIST', env) + '.pt')\n",
        "    elif env == 'all_train':\n",
        "      self.data_label_tuples = torch.load(os.path.join(self.root, 'ColoredMNIST', 'train1.pt')) + \\\n",
        "                               torch.load(os.path.join(self.root, 'ColoredMNIST', 'train2.pt'))\n",
        "    else:\n",
        "      raise RuntimeError(f'{env} env unknown. Valid envs are train1, train2, test, and all_train')\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        index (int): Index\n",
        "\n",
        "    Returns:\n",
        "        tuple: (image, target) where target is index of the target class.\n",
        "    \"\"\"\n",
        "    img, target = self.data_label_tuples[index]\n",
        "\n",
        "    if self.transform is not None:\n",
        "      img = self.transform(img)\n",
        "\n",
        "    if self.target_transform is not None:\n",
        "      target = self.target_transform(target)\n",
        "\n",
        "    return img, target\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data_label_tuples)\n",
        "\n",
        "  def prepare_colored_mnist(self):\n",
        "    colored_mnist_dir = os.path.join(self.root, 'ColoredMNIST')\n",
        "    if os.path.exists(os.path.join(colored_mnist_dir, 'train1.pt')) \\\n",
        "        and os.path.exists(os.path.join(colored_mnist_dir, 'train2.pt')) \\\n",
        "        and os.path.exists(os.path.join(colored_mnist_dir, 'test.pt')):\n",
        "      print('Colored MNIST dataset already exists')\n",
        "      return\n",
        "\n",
        "    print('Preparing Colored MNIST')\n",
        "    train_mnist = datasets.mnist.MNIST(self.root, train=True, download=True)\n",
        "\n",
        "    train1_set = []\n",
        "    train2_set = []\n",
        "    test_set = []\n",
        "    for idx, (im, label) in enumerate(train_mnist):\n",
        "      if idx % 10000 == 0:\n",
        "        print(f'Converting image {idx}/{len(train_mnist)}')\n",
        "      im_array = np.array(im)\n",
        "\n",
        "      # Assign a binary label y to the image based on the digit\n",
        "      binary_label = 0 if label < 5 else 1\n",
        "\n",
        "      # Flip label with 25% probability\n",
        "      if np.random.uniform() < 0.25:\n",
        "        binary_label = binary_label ^ 1\n",
        "\n",
        "      # Color the image either red or green according to its possibly flipped label\n",
        "      color_red = binary_label == 0\n",
        "\n",
        "      # Flip the color with a probability e that depends on the environment\n",
        "      if idx < 20000:\n",
        "        # 20% in the first training environment\n",
        "        if np.random.uniform() < 0.2:\n",
        "          color_red = not color_red\n",
        "      elif idx < 40000:\n",
        "        # 10% in the first training environment\n",
        "        if np.random.uniform() < 0.1:\n",
        "          color_red = not color_red\n",
        "      else:\n",
        "        # 90% in the test environment\n",
        "        if np.random.uniform() < 0.9:\n",
        "          color_red = not color_red\n",
        "\n",
        "      colored_arr = color_grayscale_arr(im_array, red=color_red)\n",
        "\n",
        "      if idx < 20000:\n",
        "        train1_set.append((Image.fromarray(colored_arr), binary_label))\n",
        "      elif idx < 40000:\n",
        "        train2_set.append((Image.fromarray(colored_arr), binary_label))\n",
        "      else:\n",
        "        test_set.append((Image.fromarray(colored_arr), binary_label))\n",
        "\n",
        "      # Debug\n",
        "      # print('original label', type(label), label)\n",
        "      # print('binary label', binary_label)\n",
        "      # print('assigned color', 'red' if color_red else 'green')\n",
        "      # plt.imshow(colored_arr)\n",
        "      # plt.show()\n",
        "      # break\n",
        "\n",
        "    os.makedirs(colored_mnist_dir, exist_ok=True)\n",
        "    # dataset_utils.makedir_exist_ok(colored_mnist_dir)\n",
        "    torch.save(train1_set, os.path.join(colored_mnist_dir, 'train1.pt'))\n",
        "    torch.save(train2_set, os.path.join(colored_mnist_dir, 'train2.pt'))\n",
        "    torch.save(test_set, os.path.join(colored_mnist_dir, 'test.pt'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOnjIjK8q7UJ"
      },
      "source": [
        "### Plot the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwUoQZCyvs6T"
      },
      "source": [
        "def plot_dataset_digits(dataset):\n",
        "  fig = plt.figure(figsize=(13, 8))\n",
        "  columns = 6\n",
        "  rows = 3\n",
        "  # ax enables access to manipulate each of subplots\n",
        "  ax = []\n",
        "\n",
        "  for i in range(columns * rows):\n",
        "    img, label = dataset[i]\n",
        "    # create subplot and append to ax\n",
        "    ax.append(fig.add_subplot(rows, columns, i + 1))\n",
        "    ax[-1].set_title(\"Label: \" + str(label))  # set title\n",
        "    plt.imshow(img)\n",
        "\n",
        "  plt.show()  # finally, render the plot\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11YqxmhjrSMi"
      },
      "source": [
        "Plotting the train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDh4qJS_rQwK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "7952df1f-350d-4913-c25c-9f89bf9b9cd9"
      },
      "source": [
        "train1_set = ColoredMNIST(root='./data', env='train1')\n",
        "plot_dataset_digits(train1_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colored MNIST dataset already exists\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x576 with 18 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhsLWjOCrqWx"
      },
      "source": [
        "Plotting the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdmmW48srQyk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "0920e271-9aa0-413e-e8cb-76341b81c80b"
      },
      "source": [
        "test_set = ColoredMNIST(root='./data', env='test')\n",
        "plot_dataset_digits(test_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colored MNIST dataset already exists\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 936x576 with 18 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo3Whs4hrr-C"
      },
      "source": [
        "Notice how the correlation between color and label are reversed in the train and test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yobtL1nhsIaL"
      },
      "source": [
        "## CGES Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jleIZ9vNv5rV"
      },
      "source": [
        "## Define neural network\n",
        "\n",
        "The paper uses an MLP but a Convnet works fine too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hYJRewnv80x"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(3 * 28 * 28, 512)\n",
        "    self.fc2 = nn.Linear(512, 512)\n",
        "    self.fc3 = nn.Linear(512, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 3 * 28 * 28)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    logits = self.fc3(x).flatten()\n",
        "    return logits\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 20, 5, 1)\n",
        "    self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "    self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
        "    self.fc2 = nn.Linear(500, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = x.view(-1, 4 * 4 * 50)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    logits = self.fc2(x).flatten()\n",
        "    return logits\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj5Q6UTlwGM3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il3cATYxwIyP"
      },
      "source": [
        "## Test ERM as a baseline\n",
        "\n",
        "Using ERM as a baseline, we expect to train a neural network that uses color instead of the actual digit to classify, completely failing on the test set when the colors are switched."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2oOyMQgtKkQ"
      },
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "args = Namespace(**dict({\n",
        "  'cges': False,\n",
        "  'lamb': 0.0006,\n",
        "  'mu': 0.8,\n",
        "  'chvar': 0.2,\n",
        "  'lr': 0.0001\n",
        "}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQvgkLULwx0j"
      },
      "source": [
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFYrHkYAwx65",
        "outputId": "c117ae63-312a-438d-a7e9-2042b0acb0c7"
      },
      "source": [
        "!wandb login 28f856e56e11e0b499f7b141ce1d61b0a6671e97"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyIIrrqu0HHn"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4qZtXx_weBb"
      },
      "source": [
        "from utils import apply_cges\n",
        "import wandb\n",
        "\n",
        "def test_model(model, device, test_loader, set_name=\"test_set\", epoch=-1):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device).float()\n",
        "      output = model(data)\n",
        "      test_loss += F.binary_cross_entropy_with_logits(output, target, reduction='sum').item()  # sum up batch loss\n",
        "      pred = torch.where(torch.gt(output, torch.Tensor([0.0]).to(device)),\n",
        "                         torch.Tensor([1.0]).to(device),\n",
        "                         torch.Tensor([0.0]).to(device))  # get the index of the max log-probability\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "\n",
        "  print('Performance on {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
        "    set_name, test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "  wandb.log({str(set_name) +\"/loss\": test_loss}, step=epoch)\n",
        "  wandb.log({str(set_name) +\"/acc\": 100. * correct / len(test_loader.dataset)}, step=epoch)\n",
        "\n",
        "  return 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "\n",
        "def erm_train(args, model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device).float()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = F.binary_cross_entropy_with_logits(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if args.cges:\n",
        "        apply_cges(args, model, optimizer)\n",
        "\n",
        "  print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "            100. * batch_idx / len(train_loader), loss.item()))\n",
        "  \n",
        "  wandb.log({\"train/loss\": loss.item()}, step=epoch)\n",
        "\n",
        "\n",
        "def train_and_test_erm():\n",
        "  wandb.init(entity=\"arjunashok\", project=\"irm-notebook\", config=vars(args))\n",
        "  if args.cges:\n",
        "      wandb.run.name = \"erm-cges-\"+str(args.lamb)\n",
        "  else:\n",
        "    wandb.run.name = \"erm-plain\"\n",
        "\n",
        "\n",
        "  set_seed(0)\n",
        "\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "  kwargs = {'num_workers': 8, 'pin_memory': True} if use_cuda else {}\n",
        "  all_train_loader = torch.utils.data.DataLoader(\n",
        "    ColoredMNIST(root='./data', env='all_train',\n",
        "                 transform=transforms.Compose([\n",
        "                     transforms.ToTensor(),\n",
        "                     transforms.Normalize((0.1307, 0.1307, 0.), (0.3081, 0.3081, 0.3081))\n",
        "                   ])),\n",
        "    batch_size=64, shuffle=True, **kwargs)\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "    ColoredMNIST(root='./data', env='test', transform=transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.1307, 0.1307, 0.), (0.3081, 0.3081, 0.3081))\n",
        "    ])),\n",
        "    batch_size=1000, shuffle=True, **kwargs)\n",
        "\n",
        "  model = ConvNet().to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "  best_test_acc = 0\n",
        "\n",
        "  for epoch in range(1, 100):\n",
        "    erm_train(args, model, device, all_train_loader, optimizer, epoch)\n",
        "    test_model(model, device, all_train_loader, set_name='train_set', epoch=epoch)\n",
        "    test_acc = test_model(model, device, test_loader, epoch=epoch)\n",
        "\n",
        "    if test_acc > best_test_acc:\n",
        "      best_test_acc = test_acc\n",
        "\n",
        "    wandb.log({\"test_set/best_acc\": best_test_acc}, step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1-MgdGuwlCY"
      },
      "source": [
        "## IRM\n",
        "\n",
        "After trying lots of hyperparameters and various tricks, this implementation \n",
        "seems to consistently achieve the paper-reported values \n",
        "(train accuracy > 70%, test accuracy > 60%), though there might be a bit of\n",
        "instability depending on the random seed.\n",
        "\n",
        "The most common failure case is when the gradient norm penalty term is weighted\n",
        "too highly relative to the ERM term. In this case, Φ converges to a function that \n",
        "returns the same value for all inputs. The classifier cannot recover from this point\n",
        "and the accuracy is stuck at 50% for all environments. This makes sense mathematically.\n",
        "If the intermediate representation is the same regardless of input, then *any*\n",
        "classifier is the ideal classifier, resulting in the penalty gradient being 0.\n",
        "\n",
        "Another failure case is when the gradient norm penalty is too low and the\n",
        "optimization essentially acts as in ERM (train accuracy > 80%, test accuracy ~10%).\n",
        "\n",
        "The most important trick I used to get this to work is through scheduled \n",
        "increase of the gradient norm penalty weight.\n",
        "We start at 0 for the gradient norm penalty weight, essentially beginning as ERM,\n",
        "then slowly increase it per epoch.\n",
        "\n",
        "I use early stopping to stop training once the accuracy on all environments, \n",
        "including the test set, reach an acceptable value. Yes, stopping training based on \n",
        "performance on the test set is not good practice, but I could not\n",
        "find a principled way of stopping training by only observing performance on the\n",
        "training environments. One thing that might be needed when applying IRM to\n",
        "real-world datasets is to leave out a separate environment as a validation set,\n",
        "which we can use for early stopping. The downside is we'll need a minimum of 4\n",
        "environments to perform IRM (2 train, 1 validation, 1 test)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kio2CQOdwqA9"
      },
      "source": [
        "def compute_irm_penalty(losses, dummy):\n",
        "  g1 = grad(losses[0::2].mean(), dummy, create_graph=True)[0]\n",
        "  g2 = grad(losses[1::2].mean(), dummy, create_graph=True)[0]\n",
        "  return (g1 * g2).sum()\n",
        "\n",
        "\n",
        "def irm_train(args, model, device, train_loaders, optimizer, epoch):\n",
        "  model.train()\n",
        "\n",
        "  train_loaders = [iter(x) for x in train_loaders]\n",
        "\n",
        "  dummy_w = torch.nn.Parameter(torch.Tensor([1.0])).to(device)\n",
        "\n",
        "  batch_idx = 0\n",
        "  penalty_multiplier = epoch ** 1.6\n",
        "  print(f'Using penalty multiplier {penalty_multiplier}')\n",
        "  while True:\n",
        "    optimizer.zero_grad()\n",
        "    error = 0\n",
        "    penalty = 0\n",
        "    for loader in train_loaders:\n",
        "      data, target = next(loader, (None, None))\n",
        "      if data is None:\n",
        "        return\n",
        "      data, target = data.to(device), target.to(device).float()\n",
        "      output = model(data)\n",
        "      loss_erm = F.binary_cross_entropy_with_logits(output * dummy_w, target, reduction='none')\n",
        "      penalty += compute_irm_penalty(loss_erm, dummy_w)\n",
        "      error += loss_erm.mean()\n",
        "    (error + penalty_multiplier * penalty).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if args.cges:\n",
        "      apply_cges(args, model, optimizer)\n",
        "    batch_idx += 1\n",
        "\n",
        "  print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tERM loss: {:.6f}\\tGrad penalty: {:.6f}'.format(\n",
        "    epoch, batch_idx * len(data), len(train_loaders[0]),\n",
        "            100. * batch_idx / len(train_loaders[0]), error.item(), penalty.item()))\n",
        "\n",
        "\n",
        "  wandb.log({\"train/loss\": error.item()}, step=epoch)\n",
        "  wandb.log({\"train/grad_penalty\": penalty.item()}, step=epoch)\n",
        "\n",
        "def train_and_test_irm():\n",
        "\n",
        "  import wandb\n",
        "\n",
        "  wandb.init(entity=\"arjunashok\", project=\"irm-notebook\", config=vars(args))\n",
        "  if args.cges:\n",
        "    wandb.run.name = \"irm-cges-\"+str(args.lamb)\n",
        "  else:\n",
        "    wandb.run.name = \"irm-plain\"\n",
        "\n",
        "  set_seed(0)\n",
        "\n",
        "  use_cuda = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "  kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "  train1_loader = torch.utils.data.DataLoader(\n",
        "    ColoredMNIST(root='./data', env='train1',\n",
        "                 transform=transforms.Compose([\n",
        "                     transforms.ToTensor(),\n",
        "                     transforms.Normalize((0.1307, 0.1307, 0.), (0.3081, 0.3081, 0.3081))\n",
        "                   ])),\n",
        "    batch_size=2000, shuffle=True, **kwargs)\n",
        "\n",
        "  train2_loader = torch.utils.data.DataLoader(\n",
        "    ColoredMNIST(root='./data', env='train2',\n",
        "                 transform=transforms.Compose([\n",
        "                     transforms.ToTensor(),\n",
        "                     transforms.Normalize((0.1307, 0.1307, 0.), (0.3081, 0.3081, 0.3081))\n",
        "                   ])),\n",
        "    batch_size=2000, shuffle=True, **kwargs)\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "    ColoredMNIST(root='./data', env='test', transform=transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.1307, 0.1307, 0.), (0.3081, 0.3081, 0.3081))\n",
        "    ])),\n",
        "    batch_size=1000, shuffle=True, **kwargs)\n",
        "\n",
        "  model = ConvNet().to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "  print(args)\n",
        "\n",
        "  best_test_acc = 0\n",
        "\n",
        "  for epoch in range(1, 100):\n",
        "    irm_train(args, model, device, [train1_loader, train2_loader], optimizer, epoch)\n",
        "    train1_acc = test_model(model, device, train1_loader, set_name='train1_set', epoch=epoch)\n",
        "    train2_acc = test_model(model, device, train2_loader, set_name='train2_set', epoch=epoch)\n",
        "    test_acc = test_model(model, device, test_loader, epoch=epoch)\n",
        "\n",
        "    if test_acc > best_test_acc:\n",
        "      best_test_acc = test_acc\n",
        "\n",
        "    wandb.log({\"test_set/best_acc\": best_test_acc}, step=epoch)\n",
        "\n",
        "    # if train1_acc > 70 and train2_acc > 70 and test_acc > 60:\n",
        "    #   print('found acceptable values. stopping training.')\n",
        "    #   return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGh00cHNxpPb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731,
          "referenced_widgets": [
            "8f9edac603a84c60993b2cdc8c8a2fbd",
            "b7be1a56cd99483cb1116fb032949e45",
            "303f4ce7d1d442179945e946a72595ca",
            "5ae0ac86752049f08f5a33f94aacaf01",
            "1b4f8eae681f4b17bd08745f04861bba",
            "43314268dcf742dfb653d3ea1627a66a",
            "613349fa88464589aab0e60082c225bd",
            "bda3a6513e7b49919333b08a766a3e4d"
          ]
        },
        "outputId": "170f423b-c513-4744-a353-f607c6041c0b"
      },
      "source": [
        "args.cges = True\n",
        "\n",
        "train_and_test_erm()\n",
        "train_and_test_irm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:3dvtqg43) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 30439<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f9edac603a84c60993b2cdc8c8a2fbd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.43MB of 0.43MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210915_130215-3dvtqg43/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210915_130215-3dvtqg43/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">cosmic-silence-27</strong>: <a href=\"https://wandb.ai/arjunashok/irm-notebook/runs/3dvtqg43\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook/runs/3dvtqg43</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:3dvtqg43). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">sage-dragon-28</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/arjunashok/irm-notebook\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/arjunashok/irm-notebook/runs/c6epzm59\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook/runs/c6epzm59</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210915_130655-c6epzm59</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colored MNIST dataset already exists\n",
            "Colored MNIST dataset already exists\n",
            "Colored MNIST dataset already exists\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-c05538176e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train_and_test_erm()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_and_test_irm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-ff2a67026351>\u001b[0m in \u001b[0;36mtrain_and_test_irm\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m     batch_size=1000, shuffle=True, **kwargs)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f635414bed3b408e8c62be7b9e04b4c1",
            "eaafa163ac504739ae3d70b2e641bf9d",
            "5b5f241f79434d028a1c0d04608b6eaa",
            "862fe77b603644f486a198767d718e50",
            "5dca90b787ce4f1989b937c8410ba98c",
            "24924c4110834743b73030849f31c4d9",
            "91036b4b4645424bb3b6b6d03182dcb3",
            "cb54edfc06814aac8dc790cde7b0135f",
            "1101c46da9e1466ca29007e744596084",
            "527e4e7e9b744a7b83672816d1d7c22d",
            "eeb525052d2141a590c2235ccad22a3b",
            "4525f726dc07422185b1f1e629240266",
            "b44fae64bf564aa6b67b2403e7fdb87b",
            "f5f8d6b20fac4a34b8a11c2c8bf07e63",
            "6b770d6231aa4b50a6018765a291790d",
            "63eabd93958a46f1b2c3b713d01d4b07"
          ]
        },
        "id": "nHjQGfRcPMwN",
        "outputId": "7deff41c-bea3-4d68-b5d0-6c01c958fdfb"
      },
      "source": [
        "args.cges = False\n",
        "\n",
        "train_and_test_erm()\n",
        "train_and_test_irm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:2ukd9k5g) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 14139<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f635414bed3b408e8c62be7b9e04b4c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210915_111329-2ukd9k5g/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210915_111329-2ukd9k5g/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>train1_set/loss</td><td>0.64013</td></tr><tr><td>train1_set/acc</td><td>61.455</td></tr><tr><td>train2_set/loss</td><td>0.63886</td></tr><tr><td>train2_set/acc</td><td>60.23</td></tr><tr><td>test_set/loss</td><td>0.70003</td></tr><tr><td>test_set/acc</td><td>59.76</td></tr><tr><td>test_set/best_acc</td><td>61.445</td></tr><tr><td>_runtime</td><td>2051</td></tr><tr><td>_timestamp</td><td>1631706467</td></tr><tr><td>_step</td><td>99</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>train1_set/loss</td><td>▆▂▁▂▆▅▆▇▇▇▇▇███▇██▇████▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train1_set/acc</td><td>████▃▄▃▂▂▂▂▂▁▁▁▂▂▂▂▂▁▁▁▂▂▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>train2_set/loss</td><td>▆▁▁▂▅▅▆▇▇▇▇▇███▇█████████▇█▇█▇▇███████▇█</td></tr><tr><td>train2_set/acc</td><td>████▃▃▃▂▂▂▂▂▁▁▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▂▂▁▂▂▂▂▁▂▂▂</td></tr><tr><td>test_set/loss</td><td>▂█▇█▄▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_set/acc</td><td>▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇███████████████████</td></tr><tr><td>test_set/best_acc</td><td>▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">morning-star-22</strong>: <a href=\"https://wandb.ai/arjunashok/irm-notebook/runs/2ukd9k5g\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook/runs/2ukd9k5g</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:2ukd9k5g). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">playful-mountain-23</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/arjunashok/irm-notebook\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/arjunashok/irm-notebook/runs/1ijmqzdp\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook/runs/1ijmqzdp</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210915_114747-1ijmqzdp</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colored MNIST dataset already exists\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colored MNIST dataset already exists\n",
            "Train Epoch: 1 [39936/40000 (100%)]\tLoss: 0.322680\n",
            "Performance on train_set: Average loss: 0.3826, Accuracy: 34025/40000 (85.06%)\n",
            "Performance on test_set: Average loss: 1.4425, Accuracy: 2141/20000 (10.71%)\n",
            "Train Epoch: 2 [39936/40000 (100%)]\tLoss: 0.439531\n",
            "Performance on train_set: Average loss: 0.3750, Accuracy: 33927/40000 (84.82%)\n",
            "Performance on test_set: Average loss: 1.5129, Accuracy: 2587/20000 (12.94%)\n",
            "Train Epoch: 3 [39936/40000 (100%)]\tLoss: 0.291205\n",
            "Performance on train_set: Average loss: 0.3640, Accuracy: 34007/40000 (85.02%)\n",
            "Performance on test_set: Average loss: 1.5381, Accuracy: 2231/20000 (11.15%)\n",
            "Train Epoch: 4 [39936/40000 (100%)]\tLoss: 0.401787\n",
            "Performance on train_set: Average loss: 0.3595, Accuracy: 34036/40000 (85.09%)\n",
            "Performance on test_set: Average loss: 1.4937, Accuracy: 2167/20000 (10.84%)\n",
            "Train Epoch: 5 [39936/40000 (100%)]\tLoss: 0.505517\n",
            "Performance on train_set: Average loss: 0.3615, Accuracy: 33998/40000 (85.00%)\n",
            "Performance on test_set: Average loss: 1.5635, Accuracy: 2472/20000 (12.36%)\n",
            "Train Epoch: 6 [39936/40000 (100%)]\tLoss: 0.331414\n",
            "Performance on train_set: Average loss: 0.3552, Accuracy: 34055/40000 (85.14%)\n",
            "Performance on test_set: Average loss: 1.4498, Accuracy: 2477/20000 (12.38%)\n",
            "Train Epoch: 7 [39936/40000 (100%)]\tLoss: 0.261675\n",
            "Performance on train_set: Average loss: 0.3601, Accuracy: 33844/40000 (84.61%)\n",
            "Performance on test_set: Average loss: 1.4034, Accuracy: 3756/20000 (18.78%)\n",
            "Train Epoch: 8 [39936/40000 (100%)]\tLoss: 0.296292\n",
            "Performance on train_set: Average loss: 0.3480, Accuracy: 34104/40000 (85.26%)\n",
            "Performance on test_set: Average loss: 1.4761, Accuracy: 2326/20000 (11.63%)\n",
            "Train Epoch: 9 [39936/40000 (100%)]\tLoss: 0.345972\n",
            "Performance on train_set: Average loss: 0.3467, Accuracy: 34169/40000 (85.42%)\n",
            "Performance on test_set: Average loss: 1.3485, Accuracy: 2901/20000 (14.51%)\n",
            "Train Epoch: 10 [39936/40000 (100%)]\tLoss: 0.318535\n",
            "Performance on train_set: Average loss: 0.3422, Accuracy: 34193/40000 (85.48%)\n",
            "Performance on test_set: Average loss: 1.5215, Accuracy: 2836/20000 (14.18%)\n",
            "Train Epoch: 11 [39936/40000 (100%)]\tLoss: 0.272781\n",
            "Performance on train_set: Average loss: 0.3418, Accuracy: 34217/40000 (85.54%)\n",
            "Performance on test_set: Average loss: 1.4595, Accuracy: 3586/20000 (17.93%)\n",
            "Train Epoch: 12 [39936/40000 (100%)]\tLoss: 0.426549\n",
            "Performance on train_set: Average loss: 0.3343, Accuracy: 34214/40000 (85.53%)\n",
            "Performance on test_set: Average loss: 1.5685, Accuracy: 2482/20000 (12.41%)\n",
            "Train Epoch: 13 [39936/40000 (100%)]\tLoss: 0.301961\n",
            "Performance on train_set: Average loss: 0.3298, Accuracy: 34369/40000 (85.92%)\n",
            "Performance on test_set: Average loss: 1.4637, Accuracy: 3093/20000 (15.46%)\n",
            "Train Epoch: 14 [39936/40000 (100%)]\tLoss: 0.271531\n",
            "Performance on train_set: Average loss: 0.3261, Accuracy: 34506/40000 (86.27%)\n",
            "Performance on test_set: Average loss: 1.4703, Accuracy: 3283/20000 (16.41%)\n",
            "Train Epoch: 15 [39936/40000 (100%)]\tLoss: 0.268861\n",
            "Performance on train_set: Average loss: 0.3261, Accuracy: 34499/40000 (86.25%)\n",
            "Performance on test_set: Average loss: 1.4650, Accuracy: 4238/20000 (21.19%)\n",
            "Train Epoch: 16 [39936/40000 (100%)]\tLoss: 0.258406\n",
            "Performance on train_set: Average loss: 0.3239, Accuracy: 34504/40000 (86.26%)\n",
            "Performance on test_set: Average loss: 1.5177, Accuracy: 4554/20000 (22.77%)\n",
            "Train Epoch: 17 [39936/40000 (100%)]\tLoss: 0.353244\n",
            "Performance on train_set: Average loss: 0.3136, Accuracy: 34678/40000 (86.69%)\n",
            "Performance on test_set: Average loss: 1.5713, Accuracy: 3799/20000 (19.00%)\n",
            "Train Epoch: 18 [39936/40000 (100%)]\tLoss: 0.253468\n",
            "Performance on train_set: Average loss: 0.3080, Accuracy: 34689/40000 (86.72%)\n",
            "Performance on test_set: Average loss: 1.6372, Accuracy: 3344/20000 (16.72%)\n",
            "Train Epoch: 19 [39936/40000 (100%)]\tLoss: 0.259008\n",
            "Performance on train_set: Average loss: 0.3010, Accuracy: 34936/40000 (87.34%)\n",
            "Performance on test_set: Average loss: 1.5809, Accuracy: 4394/20000 (21.97%)\n",
            "Train Epoch: 20 [39936/40000 (100%)]\tLoss: 0.295726\n",
            "Performance on train_set: Average loss: 0.2964, Accuracy: 35047/40000 (87.62%)\n",
            "Performance on test_set: Average loss: 1.6411, Accuracy: 3997/20000 (19.98%)\n",
            "Train Epoch: 21 [39936/40000 (100%)]\tLoss: 0.352680\n",
            "Performance on train_set: Average loss: 0.2919, Accuracy: 35105/40000 (87.76%)\n",
            "Performance on test_set: Average loss: 1.5444, Accuracy: 5252/20000 (26.26%)\n",
            "Train Epoch: 22 [39936/40000 (100%)]\tLoss: 0.286025\n",
            "Performance on train_set: Average loss: 0.3011, Accuracy: 34820/40000 (87.05%)\n",
            "Performance on test_set: Average loss: 1.6007, Accuracy: 5761/20000 (28.80%)\n",
            "Train Epoch: 23 [39936/40000 (100%)]\tLoss: 0.270315\n",
            "Performance on train_set: Average loss: 0.2751, Accuracy: 35534/40000 (88.83%)\n",
            "Performance on test_set: Average loss: 1.6372, Accuracy: 4523/20000 (22.61%)\n",
            "Train Epoch: 24 [39936/40000 (100%)]\tLoss: 0.295424\n",
            "Performance on train_set: Average loss: 0.2724, Accuracy: 35553/40000 (88.88%)\n",
            "Performance on test_set: Average loss: 1.6150, Accuracy: 5474/20000 (27.37%)\n",
            "Train Epoch: 25 [39936/40000 (100%)]\tLoss: 0.258511\n",
            "Performance on train_set: Average loss: 0.2621, Accuracy: 35825/40000 (89.56%)\n",
            "Performance on test_set: Average loss: 1.7226, Accuracy: 4861/20000 (24.30%)\n",
            "Train Epoch: 26 [39936/40000 (100%)]\tLoss: 0.189664\n",
            "Performance on train_set: Average loss: 0.2596, Accuracy: 35846/40000 (89.61%)\n",
            "Performance on test_set: Average loss: 1.7065, Accuracy: 5175/20000 (25.88%)\n",
            "Train Epoch: 27 [39936/40000 (100%)]\tLoss: 0.234135\n",
            "Performance on train_set: Average loss: 0.2506, Accuracy: 35891/40000 (89.73%)\n",
            "Performance on test_set: Average loss: 1.8311, Accuracy: 4710/20000 (23.55%)\n",
            "Train Epoch: 28 [39936/40000 (100%)]\tLoss: 0.322780\n",
            "Performance on train_set: Average loss: 0.2457, Accuracy: 36031/40000 (90.08%)\n",
            "Performance on test_set: Average loss: 1.7677, Accuracy: 5341/20000 (26.70%)\n",
            "Train Epoch: 29 [39936/40000 (100%)]\tLoss: 0.201607\n",
            "Performance on train_set: Average loss: 0.2460, Accuracy: 35962/40000 (89.91%)\n",
            "Performance on test_set: Average loss: 1.9809, Accuracy: 4663/20000 (23.32%)\n",
            "Train Epoch: 30 [39936/40000 (100%)]\tLoss: 0.375478\n",
            "Performance on train_set: Average loss: 0.2315, Accuracy: 36404/40000 (91.01%)\n",
            "Performance on test_set: Average loss: 1.7899, Accuracy: 5659/20000 (28.30%)\n",
            "Train Epoch: 31 [39936/40000 (100%)]\tLoss: 0.389017\n",
            "Performance on train_set: Average loss: 0.2319, Accuracy: 36342/40000 (90.86%)\n",
            "Performance on test_set: Average loss: 1.8855, Accuracy: 5593/20000 (27.96%)\n",
            "Train Epoch: 32 [39936/40000 (100%)]\tLoss: 0.285501\n",
            "Performance on train_set: Average loss: 0.2260, Accuracy: 36464/40000 (91.16%)\n",
            "Performance on test_set: Average loss: 1.8954, Accuracy: 5436/20000 (27.18%)\n",
            "Train Epoch: 33 [39936/40000 (100%)]\tLoss: 0.223678\n",
            "Performance on train_set: Average loss: 0.2174, Accuracy: 36628/40000 (91.57%)\n",
            "Performance on test_set: Average loss: 1.8873, Accuracy: 5818/20000 (29.09%)\n",
            "Train Epoch: 34 [39936/40000 (100%)]\tLoss: 0.182291\n",
            "Performance on train_set: Average loss: 0.2090, Accuracy: 36676/40000 (91.69%)\n",
            "Performance on test_set: Average loss: 2.0353, Accuracy: 5198/20000 (25.99%)\n",
            "Train Epoch: 35 [39936/40000 (100%)]\tLoss: 0.239403\n",
            "Performance on train_set: Average loss: 0.2015, Accuracy: 36864/40000 (92.16%)\n",
            "Performance on test_set: Average loss: 2.0732, Accuracy: 5347/20000 (26.73%)\n",
            "Train Epoch: 36 [39936/40000 (100%)]\tLoss: 0.152308\n",
            "Performance on train_set: Average loss: 0.2096, Accuracy: 36574/40000 (91.44%)\n",
            "Performance on test_set: Average loss: 2.2535, Accuracy: 5337/20000 (26.68%)\n",
            "Train Epoch: 37 [39936/40000 (100%)]\tLoss: 0.290741\n",
            "Performance on train_set: Average loss: 0.2001, Accuracy: 37007/40000 (92.52%)\n",
            "Performance on test_set: Average loss: 1.8847, Accuracy: 6522/20000 (32.61%)\n",
            "Train Epoch: 38 [39936/40000 (100%)]\tLoss: 0.216052\n",
            "Performance on train_set: Average loss: 0.1867, Accuracy: 37182/40000 (92.95%)\n",
            "Performance on test_set: Average loss: 2.1482, Accuracy: 5605/20000 (28.02%)\n",
            "Train Epoch: 39 [39936/40000 (100%)]\tLoss: 0.142741\n",
            "Performance on train_set: Average loss: 0.1862, Accuracy: 37163/40000 (92.91%)\n",
            "Performance on test_set: Average loss: 2.1336, Accuracy: 5956/20000 (29.78%)\n",
            "Train Epoch: 40 [39936/40000 (100%)]\tLoss: 0.157685\n",
            "Performance on train_set: Average loss: 0.1821, Accuracy: 37140/40000 (92.85%)\n",
            "Performance on test_set: Average loss: 2.2596, Accuracy: 5931/20000 (29.66%)\n",
            "Train Epoch: 41 [39936/40000 (100%)]\tLoss: 0.125233\n",
            "Performance on train_set: Average loss: 0.1724, Accuracy: 37459/40000 (93.65%)\n",
            "Performance on test_set: Average loss: 2.2257, Accuracy: 5970/20000 (29.85%)\n",
            "Train Epoch: 42 [39936/40000 (100%)]\tLoss: 0.129675\n",
            "Performance on train_set: Average loss: 0.1716, Accuracy: 37443/40000 (93.61%)\n",
            "Performance on test_set: Average loss: 2.2407, Accuracy: 6279/20000 (31.39%)\n",
            "Train Epoch: 43 [39936/40000 (100%)]\tLoss: 0.364785\n",
            "Performance on train_set: Average loss: 0.1738, Accuracy: 37317/40000 (93.29%)\n",
            "Performance on test_set: Average loss: 2.4457, Accuracy: 5758/20000 (28.79%)\n",
            "Train Epoch: 44 [39936/40000 (100%)]\tLoss: 0.197187\n",
            "Performance on train_set: Average loss: 0.1562, Accuracy: 37712/40000 (94.28%)\n",
            "Performance on test_set: Average loss: 2.4308, Accuracy: 5942/20000 (29.71%)\n",
            "Train Epoch: 45 [39936/40000 (100%)]\tLoss: 0.214580\n",
            "Performance on train_set: Average loss: 0.1771, Accuracy: 37206/40000 (93.02%)\n",
            "Performance on test_set: Average loss: 2.3238, Accuracy: 6460/20000 (32.30%)\n",
            "Train Epoch: 46 [39936/40000 (100%)]\tLoss: 0.177882\n",
            "Performance on train_set: Average loss: 0.1523, Accuracy: 37688/40000 (94.22%)\n",
            "Performance on test_set: Average loss: 2.5835, Accuracy: 5824/20000 (29.12%)\n",
            "Train Epoch: 47 [39936/40000 (100%)]\tLoss: 0.195408\n",
            "Performance on train_set: Average loss: 0.1569, Accuracy: 37663/40000 (94.16%)\n",
            "Performance on test_set: Average loss: 2.2933, Accuracy: 6806/20000 (34.03%)\n",
            "Train Epoch: 48 [39936/40000 (100%)]\tLoss: 0.153169\n",
            "Performance on train_set: Average loss: 0.1444, Accuracy: 37903/40000 (94.76%)\n",
            "Performance on test_set: Average loss: 2.5026, Accuracy: 6478/20000 (32.39%)\n",
            "Train Epoch: 49 [39936/40000 (100%)]\tLoss: 0.176403\n",
            "Performance on train_set: Average loss: 0.1394, Accuracy: 37869/40000 (94.67%)\n",
            "Performance on test_set: Average loss: 2.8377, Accuracy: 5629/20000 (28.14%)\n",
            "Train Epoch: 50 [39936/40000 (100%)]\tLoss: 0.112262\n",
            "Performance on train_set: Average loss: 0.1335, Accuracy: 37912/40000 (94.78%)\n",
            "Performance on test_set: Average loss: 3.0495, Accuracy: 5305/20000 (26.52%)\n",
            "Train Epoch: 51 [39936/40000 (100%)]\tLoss: 0.153622\n",
            "Performance on train_set: Average loss: 0.1219, Accuracy: 38349/40000 (95.87%)\n",
            "Performance on test_set: Average loss: 2.7517, Accuracy: 6054/20000 (30.27%)\n",
            "Train Epoch: 52 [39936/40000 (100%)]\tLoss: 0.132257\n",
            "Performance on train_set: Average loss: 0.1197, Accuracy: 38290/40000 (95.72%)\n",
            "Performance on test_set: Average loss: 2.9831, Accuracy: 5574/20000 (27.87%)\n",
            "Train Epoch: 53 [39936/40000 (100%)]\tLoss: 0.161639\n",
            "Performance on train_set: Average loss: 0.1165, Accuracy: 38488/40000 (96.22%)\n",
            "Performance on test_set: Average loss: 2.7466, Accuracy: 6548/20000 (32.74%)\n",
            "Train Epoch: 54 [39936/40000 (100%)]\tLoss: 0.110265\n",
            "Performance on train_set: Average loss: 0.1158, Accuracy: 38451/40000 (96.13%)\n",
            "Performance on test_set: Average loss: 2.7429, Accuracy: 6464/20000 (32.32%)\n",
            "Train Epoch: 55 [39936/40000 (100%)]\tLoss: 0.160547\n",
            "Performance on train_set: Average loss: 0.1098, Accuracy: 38488/40000 (96.22%)\n",
            "Performance on test_set: Average loss: 3.0731, Accuracy: 6311/20000 (31.55%)\n",
            "Train Epoch: 56 [39936/40000 (100%)]\tLoss: 0.203189\n",
            "Performance on train_set: Average loss: 0.1030, Accuracy: 38663/40000 (96.66%)\n",
            "Performance on test_set: Average loss: 3.0642, Accuracy: 6221/20000 (31.11%)\n",
            "Train Epoch: 57 [39936/40000 (100%)]\tLoss: 0.170148\n",
            "Performance on train_set: Average loss: 0.1116, Accuracy: 38368/40000 (95.92%)\n",
            "Performance on test_set: Average loss: 3.1537, Accuracy: 6403/20000 (32.02%)\n",
            "Train Epoch: 58 [39936/40000 (100%)]\tLoss: 0.204981\n",
            "Performance on train_set: Average loss: 0.0919, Accuracy: 38843/40000 (97.11%)\n",
            "Performance on test_set: Average loss: 3.2063, Accuracy: 6257/20000 (31.29%)\n",
            "Train Epoch: 59 [39936/40000 (100%)]\tLoss: 0.130252\n",
            "Performance on train_set: Average loss: 0.0911, Accuracy: 38825/40000 (97.06%)\n",
            "Performance on test_set: Average loss: 3.3416, Accuracy: 6063/20000 (30.32%)\n",
            "Train Epoch: 60 [39936/40000 (100%)]\tLoss: 0.151903\n",
            "Performance on train_set: Average loss: 0.0967, Accuracy: 38729/40000 (96.82%)\n",
            "Performance on test_set: Average loss: 3.1664, Accuracy: 6607/20000 (33.03%)\n",
            "Train Epoch: 61 [39936/40000 (100%)]\tLoss: 0.077517\n",
            "Performance on train_set: Average loss: 0.0857, Accuracy: 38785/40000 (96.96%)\n",
            "Performance on test_set: Average loss: 3.6316, Accuracy: 6083/20000 (30.41%)\n",
            "Train Epoch: 62 [39936/40000 (100%)]\tLoss: 0.079466\n",
            "Performance on train_set: Average loss: 0.0835, Accuracy: 38901/40000 (97.25%)\n",
            "Performance on test_set: Average loss: 3.5657, Accuracy: 6261/20000 (31.30%)\n",
            "Train Epoch: 63 [39936/40000 (100%)]\tLoss: 0.097104\n",
            "Performance on train_set: Average loss: 0.0774, Accuracy: 39034/40000 (97.58%)\n",
            "Performance on test_set: Average loss: 3.6612, Accuracy: 6389/20000 (31.95%)\n",
            "Train Epoch: 64 [39936/40000 (100%)]\tLoss: 0.090288\n",
            "Performance on train_set: Average loss: 0.0790, Accuracy: 38939/40000 (97.35%)\n",
            "Performance on test_set: Average loss: 3.8046, Accuracy: 6065/20000 (30.32%)\n",
            "Train Epoch: 65 [39936/40000 (100%)]\tLoss: 0.136688\n",
            "Performance on train_set: Average loss: 0.0738, Accuracy: 39048/40000 (97.62%)\n",
            "Performance on test_set: Average loss: 3.7656, Accuracy: 6332/20000 (31.66%)\n",
            "Train Epoch: 66 [39936/40000 (100%)]\tLoss: 0.105158\n",
            "Performance on train_set: Average loss: 0.0755, Accuracy: 38964/40000 (97.41%)\n",
            "Performance on test_set: Average loss: 4.3554, Accuracy: 5454/20000 (27.27%)\n",
            "Train Epoch: 67 [39936/40000 (100%)]\tLoss: 0.057534\n",
            "Performance on train_set: Average loss: 0.0707, Accuracy: 39064/40000 (97.66%)\n",
            "Performance on test_set: Average loss: 4.1123, Accuracy: 6100/20000 (30.50%)\n",
            "Train Epoch: 68 [39936/40000 (100%)]\tLoss: 0.052415\n",
            "Performance on train_set: Average loss: 0.0684, Accuracy: 39059/40000 (97.65%)\n",
            "Performance on test_set: Average loss: 4.3462, Accuracy: 5992/20000 (29.96%)\n",
            "Train Epoch: 69 [39936/40000 (100%)]\tLoss: 0.050084\n",
            "Performance on train_set: Average loss: 0.0594, Accuracy: 39340/40000 (98.35%)\n",
            "Performance on test_set: Average loss: 3.9776, Accuracy: 6358/20000 (31.79%)\n",
            "Train Epoch: 70 [39936/40000 (100%)]\tLoss: 0.110280\n",
            "Performance on train_set: Average loss: 0.0620, Accuracy: 39241/40000 (98.10%)\n",
            "Performance on test_set: Average loss: 4.1903, Accuracy: 6544/20000 (32.72%)\n",
            "Train Epoch: 71 [39936/40000 (100%)]\tLoss: 0.081013\n",
            "Performance on train_set: Average loss: 0.0532, Accuracy: 39417/40000 (98.54%)\n",
            "Performance on test_set: Average loss: 4.2638, Accuracy: 6311/20000 (31.55%)\n",
            "Train Epoch: 72 [39936/40000 (100%)]\tLoss: 0.084300\n",
            "Performance on train_set: Average loss: 0.0547, Accuracy: 39323/40000 (98.31%)\n",
            "Performance on test_set: Average loss: 4.4898, Accuracy: 6251/20000 (31.25%)\n",
            "Train Epoch: 73 [39936/40000 (100%)]\tLoss: 0.065374\n",
            "Performance on train_set: Average loss: 0.0616, Accuracy: 39110/40000 (97.78%)\n",
            "Performance on test_set: Average loss: 4.8133, Accuracy: 5988/20000 (29.94%)\n",
            "Train Epoch: 74 [39936/40000 (100%)]\tLoss: 0.146893\n",
            "Performance on train_set: Average loss: 0.0628, Accuracy: 39146/40000 (97.86%)\n",
            "Performance on test_set: Average loss: 4.5130, Accuracy: 6226/20000 (31.13%)\n",
            "Train Epoch: 75 [39936/40000 (100%)]\tLoss: 0.126939\n",
            "Performance on train_set: Average loss: 0.0498, Accuracy: 39336/40000 (98.34%)\n",
            "Performance on test_set: Average loss: 4.9293, Accuracy: 6029/20000 (30.14%)\n",
            "Train Epoch: 76 [39936/40000 (100%)]\tLoss: 0.054886\n",
            "Performance on train_set: Average loss: 0.0468, Accuracy: 39368/40000 (98.42%)\n",
            "Performance on test_set: Average loss: 5.0299, Accuracy: 6030/20000 (30.15%)\n",
            "Train Epoch: 77 [39936/40000 (100%)]\tLoss: 0.038348\n",
            "Performance on train_set: Average loss: 0.0405, Accuracy: 39616/40000 (99.04%)\n",
            "Performance on test_set: Average loss: 4.5513, Accuracy: 6658/20000 (33.29%)\n",
            "Train Epoch: 78 [39936/40000 (100%)]\tLoss: 0.093259\n",
            "Performance on train_set: Average loss: 0.0417, Accuracy: 39510/40000 (98.78%)\n",
            "Performance on test_set: Average loss: 5.1904, Accuracy: 5967/20000 (29.84%)\n",
            "Train Epoch: 79 [39936/40000 (100%)]\tLoss: 0.019588\n",
            "Performance on train_set: Average loss: 0.0497, Accuracy: 39290/40000 (98.22%)\n",
            "Performance on test_set: Average loss: 5.4387, Accuracy: 5759/20000 (28.80%)\n",
            "Train Epoch: 80 [39936/40000 (100%)]\tLoss: 0.051017\n",
            "Performance on train_set: Average loss: 0.0474, Accuracy: 39469/40000 (98.67%)\n",
            "Performance on test_set: Average loss: 4.8456, Accuracy: 6722/20000 (33.61%)\n",
            "Train Epoch: 81 [39936/40000 (100%)]\tLoss: 0.059834\n",
            "Performance on train_set: Average loss: 0.0670, Accuracy: 38873/40000 (97.18%)\n",
            "Performance on test_set: Average loss: 5.1083, Accuracy: 6371/20000 (31.86%)\n",
            "Train Epoch: 82 [39936/40000 (100%)]\tLoss: 0.062556\n",
            "Performance on train_set: Average loss: 0.0348, Accuracy: 39582/40000 (98.95%)\n",
            "Performance on test_set: Average loss: 5.4577, Accuracy: 6046/20000 (30.23%)\n",
            "Train Epoch: 83 [39936/40000 (100%)]\tLoss: 0.044093\n",
            "Performance on train_set: Average loss: 0.0359, Accuracy: 39562/40000 (98.91%)\n",
            "Performance on test_set: Average loss: 5.2973, Accuracy: 6511/20000 (32.55%)\n",
            "Train Epoch: 84 [39936/40000 (100%)]\tLoss: 0.021189\n",
            "Performance on train_set: Average loss: 0.0380, Accuracy: 39498/40000 (98.75%)\n",
            "Performance on test_set: Average loss: 5.6743, Accuracy: 5987/20000 (29.93%)\n",
            "Train Epoch: 85 [39936/40000 (100%)]\tLoss: 0.039782\n",
            "Performance on train_set: Average loss: 0.0297, Accuracy: 39703/40000 (99.26%)\n",
            "Performance on test_set: Average loss: 5.6457, Accuracy: 6217/20000 (31.09%)\n",
            "Train Epoch: 86 [39936/40000 (100%)]\tLoss: 0.047382\n",
            "Performance on train_set: Average loss: 0.0434, Accuracy: 39405/40000 (98.51%)\n",
            "Performance on test_set: Average loss: 5.5942, Accuracy: 6190/20000 (30.95%)\n",
            "Train Epoch: 87 [39936/40000 (100%)]\tLoss: 0.013481\n",
            "Performance on train_set: Average loss: 0.0266, Accuracy: 39770/40000 (99.42%)\n",
            "Performance on test_set: Average loss: 5.5521, Accuracy: 6446/20000 (32.23%)\n",
            "Train Epoch: 88 [39936/40000 (100%)]\tLoss: 0.023393\n",
            "Performance on train_set: Average loss: 0.0340, Accuracy: 39621/40000 (99.05%)\n",
            "Performance on test_set: Average loss: 5.3998, Accuracy: 6951/20000 (34.76%)\n",
            "Train Epoch: 89 [39936/40000 (100%)]\tLoss: 0.035613\n",
            "Performance on train_set: Average loss: 0.0384, Accuracy: 39491/40000 (98.73%)\n",
            "Performance on test_set: Average loss: 6.1146, Accuracy: 5952/20000 (29.76%)\n",
            "Train Epoch: 90 [39936/40000 (100%)]\tLoss: 0.025982\n",
            "Performance on train_set: Average loss: 0.0422, Accuracy: 39391/40000 (98.48%)\n",
            "Performance on test_set: Average loss: 6.0924, Accuracy: 6330/20000 (31.65%)\n",
            "Train Epoch: 91 [39936/40000 (100%)]\tLoss: 0.054739\n",
            "Performance on train_set: Average loss: 0.0248, Accuracy: 39732/40000 (99.33%)\n",
            "Performance on test_set: Average loss: 6.3332, Accuracy: 6127/20000 (30.64%)\n",
            "Train Epoch: 92 [39936/40000 (100%)]\tLoss: 0.021123\n",
            "Performance on train_set: Average loss: 0.0280, Accuracy: 39690/40000 (99.22%)\n",
            "Performance on test_set: Average loss: 6.2915, Accuracy: 6267/20000 (31.34%)\n",
            "Train Epoch: 93 [39936/40000 (100%)]\tLoss: 0.010009\n",
            "Performance on train_set: Average loss: 0.0247, Accuracy: 39739/40000 (99.35%)\n",
            "Performance on test_set: Average loss: 6.0811, Accuracy: 6363/20000 (31.82%)\n",
            "Train Epoch: 94 [39936/40000 (100%)]\tLoss: 0.028543\n",
            "Performance on train_set: Average loss: 0.0221, Accuracy: 39792/40000 (99.48%)\n",
            "Performance on test_set: Average loss: 6.4810, Accuracy: 6188/20000 (30.94%)\n",
            "Train Epoch: 95 [39936/40000 (100%)]\tLoss: 0.019118\n",
            "Performance on train_set: Average loss: 0.0565, Accuracy: 39186/40000 (97.97%)\n",
            "Performance on test_set: Average loss: 5.3500, Accuracy: 7439/20000 (37.20%)\n",
            "Train Epoch: 96 [39936/40000 (100%)]\tLoss: 0.029475\n",
            "Performance on train_set: Average loss: 0.0236, Accuracy: 39762/40000 (99.41%)\n",
            "Performance on test_set: Average loss: 6.0029, Accuracy: 6689/20000 (33.45%)\n",
            "Train Epoch: 97 [39936/40000 (100%)]\tLoss: 0.038728\n",
            "Performance on train_set: Average loss: 0.0268, Accuracy: 39642/40000 (99.11%)\n",
            "Performance on test_set: Average loss: 6.5217, Accuracy: 6273/20000 (31.36%)\n",
            "Train Epoch: 98 [39936/40000 (100%)]\tLoss: 0.037057\n",
            "Performance on train_set: Average loss: 0.0168, Accuracy: 39887/40000 (99.72%)\n",
            "Performance on test_set: Average loss: 6.2596, Accuracy: 6521/20000 (32.60%)\n",
            "Train Epoch: 99 [39936/40000 (100%)]\tLoss: 0.013990\n",
            "Performance on train_set: Average loss: 0.0207, Accuracy: 39780/40000 (99.45%)\n",
            "Performance on test_set: Average loss: 6.7717, Accuracy: 6231/20000 (31.16%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:1ijmqzdp) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 17148<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1101c46da9e1466ca29007e744596084",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.26MB of 0.26MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210915_114747-1ijmqzdp/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210915_114747-1ijmqzdp/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>train/loss</td><td>0.01399</td></tr><tr><td>train_set/loss</td><td>0.02074</td></tr><tr><td>train_set/acc</td><td>99.45</td></tr><tr><td>test_set/loss</td><td>6.77168</td></tr><tr><td>test_set/acc</td><td>31.155</td></tr><tr><td>test_set/best_acc</td><td>37.195</td></tr><tr><td>_runtime</td><td>2455</td></tr><tr><td>_timestamp</td><td>1631708926</td></tr><tr><td>_step</td><td>99</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>train/loss</td><td>▇▆▇▆▆▆▆▅▇▆▄▇█▅▄▅▃█▄▄▄▄▅▅▂▃▃▂▂▂▂▃▂▂▂▁▂▁▁▁</td></tr><tr><td>train_set/loss</td><td>██▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train_set/acc</td><td>▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇█▇██▇███████</td></tr><tr><td>test_set/loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇█</td></tr><tr><td>test_set/acc</td><td>▁▁▁▁▃▂▅▃▆▄▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇█▇</td></tr><tr><td>test_set/best_acc</td><td>▁▂▂▃▃▃▄▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">playful-mountain-23</strong>: <a href=\"https://wandb.ai/arjunashok/irm-notebook/runs/1ijmqzdp\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook/runs/1ijmqzdp</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:1ijmqzdp). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">cool-valley-24</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/arjunashok/irm-notebook\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/arjunashok/irm-notebook/runs/2xoy3iic\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook/runs/2xoy3iic</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210915_122843-2xoy3iic</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colored MNIST dataset already exists\n",
            "Colored MNIST dataset already exists\n",
            "Colored MNIST dataset already exists\n",
            "Namespace(cges=False, chvar=0.2, lamb=0.0006, lr=0.0001, mu=0.8)\n",
            "Using penalty multiplier 1.0\n",
            "Performance on train1_set: Average loss: 0.6018, Accuracy: 16017/20000 (80.08%)\n",
            "Performance on train2_set: Average loss: 0.5650, Accuracy: 18024/20000 (90.12%)\n",
            "Performance on test_set: Average loss: 0.8617, Accuracy: 2054/20000 (10.27%)\n",
            "Using penalty multiplier 3.0314331330207964\n",
            "Performance on train1_set: Average loss: 0.5362, Accuracy: 16017/20000 (80.08%)\n",
            "Performance on train2_set: Average loss: 0.4163, Accuracy: 18024/20000 (90.12%)\n",
            "Performance on test_set: Average loss: 1.3696, Accuracy: 2054/20000 (10.27%)\n",
            "Using penalty multiplier 5.799546134795289\n",
            "Performance on train1_set: Average loss: 0.5149, Accuracy: 16016/20000 (80.08%)\n",
            "Performance on train2_set: Average loss: 0.3567, Accuracy: 18022/20000 (90.11%)\n",
            "Performance on test_set: Average loss: 1.6209, Accuracy: 2055/20000 (10.28%)\n",
            "Using penalty multiplier 9.18958683997628\n",
            "Performance on train1_set: Average loss: 0.5125, Accuracy: 16017/20000 (80.08%)\n",
            "Performance on train2_set: Average loss: 0.3493, Accuracy: 18023/20000 (90.11%)\n",
            "Performance on test_set: Average loss: 1.6544, Accuracy: 2054/20000 (10.27%)\n",
            "Using penalty multiplier 13.132639022018838\n",
            "Performance on train1_set: Average loss: 0.5048, Accuracy: 16017/20000 (80.08%)\n",
            "Performance on train2_set: Average loss: 0.3463, Accuracy: 18024/20000 (90.12%)\n",
            "Performance on test_set: Average loss: 1.6145, Accuracy: 2054/20000 (10.27%)\n",
            "Using penalty multiplier 17.580936309501134\n",
            "Performance on train1_set: Average loss: 0.4997, Accuracy: 16017/20000 (80.08%)\n",
            "Performance on train2_set: Average loss: 0.3529, Accuracy: 18024/20000 (90.12%)\n",
            "Performance on test_set: Average loss: 1.5318, Accuracy: 2054/20000 (10.27%)\n",
            "Using penalty multiplier 22.498670948012276\n",
            "Performance on train1_set: Average loss: 0.5073, Accuracy: 16017/20000 (80.08%)\n",
            "Performance on train2_set: Average loss: 0.3449, Accuracy: 18024/20000 (90.12%)\n",
            "Performance on test_set: Average loss: 1.6524, Accuracy: 2054/20000 (10.27%)\n",
            "Using penalty multiplier 27.85761802547598\n",
            "Performance on train1_set: Average loss: 0.5236, Accuracy: 16016/20000 (80.08%)\n",
            "Performance on train2_set: Average loss: 0.3771, Accuracy: 18024/20000 (90.12%)\n",
            "Performance on test_set: Average loss: 1.5654, Accuracy: 2057/20000 (10.29%)\n",
            "Using penalty multiplier 33.63473536961897\n",
            "Performance on train1_set: Average loss: 0.5558, Accuracy: 15649/20000 (78.25%)\n",
            "Performance on train2_set: Average loss: 0.4470, Accuracy: 17412/20000 (87.06%)\n",
            "Performance on test_set: Average loss: 1.3375, Accuracy: 3473/20000 (17.36%)\n",
            "Using penalty multiplier 39.810717055349734\n",
            "Performance on train1_set: Average loss: 0.5719, Accuracy: 14507/20000 (72.53%)\n",
            "Performance on train2_set: Average loss: 0.4857, Accuracy: 15576/20000 (77.88%)\n",
            "Performance on test_set: Average loss: 1.1965, Accuracy: 6488/20000 (32.44%)\n",
            "Using penalty multiplier 46.369060464010914\n",
            "Performance on train1_set: Average loss: 0.6099, Accuracy: 12713/20000 (63.56%)\n",
            "Performance on train2_set: Average loss: 0.5411, Accuracy: 13121/20000 (65.61%)\n",
            "Performance on test_set: Average loss: 1.1150, Accuracy: 8969/20000 (44.84%)\n",
            "Using penalty multiplier 53.29543283815009\n",
            "Performance on train1_set: Average loss: 0.5860, Accuracy: 13578/20000 (67.89%)\n",
            "Performance on train2_set: Average loss: 0.5177, Accuracy: 14262/20000 (71.31%)\n",
            "Performance on test_set: Average loss: 1.0896, Accuracy: 8133/20000 (40.66%)\n",
            "Using penalty multiplier 60.57722346046887\n",
            "Performance on train1_set: Average loss: 0.5962, Accuracy: 13122/20000 (65.61%)\n",
            "Performance on train2_set: Average loss: 0.5324, Accuracy: 13671/20000 (68.36%)\n",
            "Performance on test_set: Average loss: 1.0693, Accuracy: 8645/20000 (43.23%)\n",
            "Using penalty multiplier 68.20321656073682\n",
            "Performance on train1_set: Average loss: 0.6048, Accuracy: 12778/20000 (63.89%)\n",
            "Performance on train2_set: Average loss: 0.5483, Accuracy: 13198/20000 (65.99%)\n",
            "Performance on test_set: Average loss: 1.0288, Accuracy: 8929/20000 (44.65%)\n",
            "Using penalty multiplier 76.16334587981113\n",
            "Performance on train1_set: Average loss: 0.6081, Accuracy: 12647/20000 (63.23%)\n",
            "Performance on train2_set: Average loss: 0.5562, Accuracy: 13023/20000 (65.11%)\n",
            "Performance on test_set: Average loss: 1.0006, Accuracy: 9005/20000 (45.02%)\n",
            "Using penalty multiplier 84.44850628946526\n",
            "Performance on train1_set: Average loss: 0.6067, Accuracy: 12673/20000 (63.37%)\n",
            "Performance on train2_set: Average loss: 0.5589, Accuracy: 13082/20000 (65.41%)\n",
            "Performance on test_set: Average loss: 0.9719, Accuracy: 8971/20000 (44.85%)\n",
            "Using penalty multiplier 93.05040638761433\n",
            "Performance on train1_set: Average loss: 0.6313, Accuracy: 11790/20000 (58.95%)\n",
            "Performance on train2_set: Average loss: 0.5906, Accuracy: 11952/20000 (59.76%)\n",
            "Performance on test_set: Average loss: 0.9479, Accuracy: 9405/20000 (47.02%)\n",
            "Using penalty multiplier 101.96145121984944\n",
            "Performance on train1_set: Average loss: 0.6279, Accuracy: 11989/20000 (59.95%)\n",
            "Performance on train2_set: Average loss: 0.5908, Accuracy: 12148/20000 (60.74%)\n",
            "Performance on test_set: Average loss: 0.9204, Accuracy: 9324/20000 (46.62%)\n",
            "Using penalty multiplier 111.17464760577515\n",
            "Performance on train1_set: Average loss: 0.6142, Accuracy: 12507/20000 (62.53%)\n",
            "Performance on train2_set: Average loss: 0.5770, Accuracy: 12836/20000 (64.18%)\n",
            "Performance on test_set: Average loss: 0.9085, Accuracy: 9060/20000 (45.30%)\n",
            "Using penalty multiplier 120.6835267309033\n",
            "Performance on train1_set: Average loss: 0.6432, Accuracy: 11505/20000 (57.52%)\n",
            "Performance on train2_set: Average loss: 0.6132, Accuracy: 11640/20000 (58.20%)\n",
            "Performance on test_set: Average loss: 0.8874, Accuracy: 9507/20000 (47.53%)\n",
            "Using penalty multiplier 130.48208013457565\n",
            "Performance on train1_set: Average loss: 0.6250, Accuracy: 12217/20000 (61.09%)\n",
            "Performance on train2_set: Average loss: 0.5955, Accuracy: 12488/20000 (62.44%)\n",
            "Performance on test_set: Average loss: 0.8649, Accuracy: 9230/20000 (46.15%)\n",
            "Using penalty multiplier 140.56470623764733\n",
            "Performance on train1_set: Average loss: 0.6359, Accuracy: 11824/20000 (59.12%)\n",
            "Performance on train2_set: Average loss: 0.6093, Accuracy: 12014/20000 (60.07%)\n",
            "Performance on test_set: Average loss: 0.8558, Accuracy: 9381/20000 (46.91%)\n",
            "Using penalty multiplier 150.92616526686473\n",
            "Performance on train1_set: Average loss: 0.6297, Accuracy: 12081/20000 (60.41%)\n",
            "Performance on train2_set: Average loss: 0.6031, Accuracy: 12321/20000 (61.60%)\n",
            "Performance on test_set: Average loss: 0.8499, Accuracy: 9275/20000 (46.38%)\n",
            "Using penalty multiplier 161.56154094425278\n",
            "Performance on train1_set: Average loss: 0.6296, Accuracy: 12111/20000 (60.55%)\n",
            "Performance on train2_set: Average loss: 0.6041, Accuracy: 12363/20000 (61.81%)\n",
            "Performance on test_set: Average loss: 0.8440, Accuracy: 9267/20000 (46.34%)\n",
            "Using penalty multiplier 172.4662076826519\n",
            "Performance on train1_set: Average loss: 0.6392, Accuracy: 11830/20000 (59.15%)\n",
            "Performance on train2_set: Average loss: 0.6163, Accuracy: 12049/20000 (60.24%)\n",
            "Performance on test_set: Average loss: 0.8374, Accuracy: 9375/20000 (46.88%)\n",
            "Using penalty multiplier 183.63580230447005\n",
            "Performance on train1_set: Average loss: 0.6364, Accuracy: 11989/20000 (59.95%)\n",
            "Performance on train2_set: Average loss: 0.6137, Accuracy: 12230/20000 (61.15%)\n",
            "Performance on test_set: Average loss: 0.8354, Accuracy: 9317/20000 (46.59%)\n",
            "Using penalty multiplier 195.06619950773612\n",
            "Performance on train1_set: Average loss: 0.6388, Accuracy: 12003/20000 (60.02%)\n",
            "Performance on train2_set: Average loss: 0.6179, Accuracy: 12254/20000 (61.27%)\n",
            "Performance on test_set: Average loss: 0.8273, Accuracy: 9311/20000 (46.55%)\n",
            "Using penalty multiplier 206.75349046081027\n",
            "Performance on train1_set: Average loss: 0.6336, Accuracy: 12242/20000 (61.21%)\n",
            "Performance on train2_set: Average loss: 0.6137, Accuracy: 12498/20000 (62.49%)\n",
            "Performance on test_set: Average loss: 0.8158, Accuracy: 9169/20000 (45.84%)\n",
            "Using penalty multiplier 218.69396402795164\n",
            "Performance on train1_set: Average loss: 0.6332, Accuracy: 12264/20000 (61.32%)\n",
            "Performance on train2_set: Average loss: 0.6143, Accuracy: 12518/20000 (62.59%)\n",
            "Performance on test_set: Average loss: 0.8088, Accuracy: 9155/20000 (45.77%)\n",
            "Using penalty multiplier 230.88409022178243\n",
            "Performance on train1_set: Average loss: 0.6296, Accuracy: 12374/20000 (61.87%)\n",
            "Performance on train2_set: Average loss: 0.6107, Accuracy: 12625/20000 (63.12%)\n",
            "Performance on test_set: Average loss: 0.8031, Accuracy: 9102/20000 (45.51%)\n",
            "Using penalty multiplier 243.3205055522631\n",
            "Performance on train1_set: Average loss: 0.6567, Accuracy: 11548/20000 (57.74%)\n",
            "Performance on train2_set: Average loss: 0.6455, Accuracy: 11685/20000 (58.42%)\n",
            "Performance on test_set: Average loss: 0.7744, Accuracy: 9492/20000 (47.46%)\n",
            "Using penalty multiplier 256.00000000000006\n",
            "Performance on train1_set: Average loss: 0.6581, Accuracy: 11475/20000 (57.38%)\n",
            "Performance on train2_set: Average loss: 0.6480, Accuracy: 11595/20000 (57.98%)\n",
            "Performance on test_set: Average loss: 0.7659, Accuracy: 9520/20000 (47.60%)\n",
            "Using penalty multiplier 268.91950538814353\n",
            "Performance on train1_set: Average loss: 0.6508, Accuracy: 11704/20000 (58.52%)\n",
            "Performance on train2_set: Average loss: 0.6396, Accuracy: 11886/20000 (59.43%)\n",
            "Performance on test_set: Average loss: 0.7663, Accuracy: 9429/20000 (47.15%)\n",
            "Using penalty multiplier 282.07608496446403\n",
            "Performance on train1_set: Average loss: 0.6459, Accuracy: 11743/20000 (58.72%)\n",
            "Performance on train2_set: Average loss: 0.6317, Accuracy: 11941/20000 (59.70%)\n",
            "Performance on test_set: Average loss: 0.7837, Accuracy: 9407/20000 (47.03%)\n",
            "Using penalty multiplier 295.46692403542755\n",
            "Performance on train1_set: Average loss: 0.6488, Accuracy: 11661/20000 (58.30%)\n",
            "Performance on train2_set: Average loss: 0.6351, Accuracy: 11844/20000 (59.22%)\n",
            "Performance on test_set: Average loss: 0.7854, Accuracy: 9445/20000 (47.23%)\n",
            "Using penalty multiplier 309.0893215187353\n",
            "Performance on train1_set: Average loss: 0.6436, Accuracy: 11844/20000 (59.22%)\n",
            "Performance on train2_set: Average loss: 0.6296, Accuracy: 12100/20000 (60.50%)\n",
            "Performance on test_set: Average loss: 0.7829, Accuracy: 9368/20000 (46.84%)\n",
            "Using penalty multiplier 322.94068230101703\n",
            "Performance on train1_set: Average loss: 0.6476, Accuracy: 11824/20000 (59.12%)\n",
            "Performance on train2_set: Average loss: 0.6358, Accuracy: 12054/20000 (60.27%)\n",
            "Performance on test_set: Average loss: 0.7726, Accuracy: 9416/20000 (47.08%)\n",
            "Using penalty multiplier 337.01851030405794\n",
            "Performance on train1_set: Average loss: 0.6403, Accuracy: 12099/20000 (60.49%)\n",
            "Performance on train2_set: Average loss: 0.6276, Accuracy: 12328/20000 (61.64%)\n",
            "Performance on test_set: Average loss: 0.7721, Accuracy: 9359/20000 (46.80%)\n",
            "Using penalty multiplier 351.32040217679275\n",
            "Performance on train1_set: Average loss: 0.6418, Accuracy: 12037/20000 (60.19%)\n",
            "Performance on train2_set: Average loss: 0.6289, Accuracy: 12277/20000 (61.38%)\n",
            "Performance on test_set: Average loss: 0.7770, Accuracy: 9389/20000 (46.95%)\n",
            "Using penalty multiplier 365.8440415418612\n",
            "Performance on train1_set: Average loss: 0.6435, Accuracy: 12046/20000 (60.23%)\n",
            "Performance on train2_set: Average loss: 0.6321, Accuracy: 12271/20000 (61.35%)\n",
            "Performance on test_set: Average loss: 0.7702, Accuracy: 9459/20000 (47.30%)\n",
            "Using penalty multiplier 380.58719373521416\n",
            "Performance on train1_set: Average loss: 0.6472, Accuracy: 12038/20000 (60.19%)\n",
            "Performance on train2_set: Average loss: 0.6388, Accuracy: 12224/20000 (61.12%)\n",
            "Performance on test_set: Average loss: 0.7532, Accuracy: 9733/20000 (48.66%)\n",
            "Using penalty multiplier 395.54770098542724\n",
            "Performance on train1_set: Average loss: 0.6364, Accuracy: 12430/20000 (62.15%)\n",
            "Performance on train2_set: Average loss: 0.6275, Accuracy: 12561/20000 (62.80%)\n",
            "Performance on test_set: Average loss: 0.7423, Accuracy: 10221/20000 (51.10%)\n",
            "Using penalty multiplier 410.72347798629295\n",
            "Performance on train1_set: Average loss: 0.6492, Accuracy: 12030/20000 (60.15%)\n",
            "Performance on train2_set: Average loss: 0.6440, Accuracy: 12092/20000 (60.46%)\n",
            "Performance on test_set: Average loss: 0.7285, Accuracy: 10613/20000 (53.06%)\n",
            "Using penalty multiplier 426.11250782213915\n",
            "Performance on train1_set: Average loss: 0.6511, Accuracy: 11869/20000 (59.34%)\n",
            "Performance on train2_set: Average loss: 0.6443, Accuracy: 11929/20000 (59.65%)\n",
            "Performance on test_set: Average loss: 0.7421, Accuracy: 10445/20000 (52.23%)\n",
            "Using penalty multiplier 441.71283821033535\n",
            "Performance on train1_set: Average loss: 0.6339, Accuracy: 12235/20000 (61.17%)\n",
            "Performance on train2_set: Average loss: 0.6214, Accuracy: 12398/20000 (61.99%)\n",
            "Performance on test_set: Average loss: 0.7661, Accuracy: 10099/20000 (50.49%)\n",
            "Using penalty multiplier 457.5225780297462\n",
            "Performance on train1_set: Average loss: 0.6404, Accuracy: 12119/20000 (60.59%)\n",
            "Performance on train2_set: Average loss: 0.6315, Accuracy: 12201/20000 (61.01%)\n",
            "Performance on test_set: Average loss: 0.7476, Accuracy: 10552/20000 (52.76%)\n",
            "Using penalty multiplier 473.5398941075845\n",
            "Performance on train1_set: Average loss: 0.6550, Accuracy: 11889/20000 (59.45%)\n",
            "Performance on train2_set: Average loss: 0.6527, Accuracy: 11809/20000 (59.05%)\n",
            "Performance on test_set: Average loss: 0.7133, Accuracy: 11302/20000 (56.51%)\n",
            "Using penalty multiplier 489.76300824030386\n",
            "Performance on train1_set: Average loss: 0.6477, Accuracy: 12005/20000 (60.02%)\n",
            "Performance on train2_set: Average loss: 0.6432, Accuracy: 11938/20000 (59.69%)\n",
            "Performance on test_set: Average loss: 0.7200, Accuracy: 11255/20000 (56.27%)\n",
            "Using penalty multiplier 506.19019442693155\n",
            "Performance on train1_set: Average loss: 0.6426, Accuracy: 11994/20000 (59.97%)\n",
            "Performance on train2_set: Average loss: 0.6350, Accuracy: 11979/20000 (59.90%)\n",
            "Performance on test_set: Average loss: 0.7375, Accuracy: 11044/20000 (55.22%)\n",
            "Using penalty multiplier 522.8197762956368\n",
            "Performance on train1_set: Average loss: 0.6412, Accuracy: 11903/20000 (59.52%)\n",
            "Performance on train2_set: Average loss: 0.6313, Accuracy: 11900/20000 (59.50%)\n",
            "Performance on test_set: Average loss: 0.7545, Accuracy: 10834/20000 (54.17%)\n",
            "Using penalty multiplier 539.6501247064195\n",
            "Performance on train1_set: Average loss: 0.6430, Accuracy: 11818/20000 (59.09%)\n",
            "Performance on train2_set: Average loss: 0.6325, Accuracy: 11801/20000 (59.01%)\n",
            "Performance on test_set: Average loss: 0.7630, Accuracy: 10766/20000 (53.83%)\n",
            "Using penalty multiplier 556.6796555146271\n",
            "Performance on train1_set: Average loss: 0.6439, Accuracy: 11874/20000 (59.37%)\n",
            "Performance on train2_set: Average loss: 0.6357, Accuracy: 11813/20000 (59.06%)\n",
            "Performance on test_set: Average loss: 0.7474, Accuracy: 11074/20000 (55.37%)\n",
            "Using penalty multiplier 573.9068274816058\n",
            "Performance on train1_set: Average loss: 0.6532, Accuracy: 11803/20000 (59.02%)\n",
            "Performance on train2_set: Average loss: 0.6506, Accuracy: 11631/20000 (58.16%)\n",
            "Performance on test_set: Average loss: 0.7155, Accuracy: 11599/20000 (57.99%)\n",
            "Using penalty multiplier 591.3301403201962\n",
            "Performance on train1_set: Average loss: 0.6564, Accuracy: 11676/20000 (58.38%)\n",
            "Performance on train2_set: Average loss: 0.6542, Accuracy: 11497/20000 (57.48%)\n",
            "Performance on test_set: Average loss: 0.7161, Accuracy: 11623/20000 (58.12%)\n",
            "Using penalty multiplier 608.9481328640206\n",
            "Performance on train1_set: Average loss: 0.6466, Accuracy: 11784/20000 (58.92%)\n",
            "Performance on train2_set: Average loss: 0.6396, Accuracy: 11662/20000 (58.31%)\n",
            "Performance on test_set: Average loss: 0.7417, Accuracy: 11337/20000 (56.69%)\n",
            "Using penalty multiplier 626.7593813505995\n",
            "Performance on train1_set: Average loss: 0.6520, Accuracy: 11768/20000 (58.84%)\n",
            "Performance on train2_set: Average loss: 0.6487, Accuracy: 11570/20000 (57.85%)\n",
            "Performance on test_set: Average loss: 0.7207, Accuracy: 11719/20000 (58.59%)\n",
            "Using penalty multiplier 644.7624978093015\n",
            "Performance on train1_set: Average loss: 0.6470, Accuracy: 11924/20000 (59.62%)\n",
            "Performance on train2_set: Average loss: 0.6442, Accuracy: 11747/20000 (58.73%)\n",
            "Performance on test_set: Average loss: 0.7123, Accuracy: 11807/20000 (59.03%)\n",
            "Using penalty multiplier 662.9561285459907\n",
            "Performance on train1_set: Average loss: 0.6392, Accuracy: 12047/20000 (60.23%)\n",
            "Performance on train2_set: Average loss: 0.6327, Accuracy: 11914/20000 (59.57%)\n",
            "Performance on test_set: Average loss: 0.7310, Accuracy: 11604/20000 (58.02%)\n",
            "Using penalty multiplier 681.338952716991\n",
            "Performance on train1_set: Average loss: 0.6386, Accuracy: 11970/20000 (59.85%)\n",
            "Performance on train2_set: Average loss: 0.6297, Accuracy: 11854/20000 (59.27%)\n",
            "Performance on test_set: Average loss: 0.7500, Accuracy: 11491/20000 (57.45%)\n",
            "Using penalty multiplier 699.9096809856741\n",
            "Performance on train1_set: Average loss: 0.6330, Accuracy: 12070/20000 (60.35%)\n",
            "Performance on train2_set: Average loss: 0.6216, Accuracy: 11987/20000 (59.94%)\n",
            "Performance on test_set: Average loss: 0.7643, Accuracy: 11305/20000 (56.52%)\n",
            "Using penalty multiplier 718.6670542555771\n",
            "Performance on train1_set: Average loss: 0.6375, Accuracy: 12072/20000 (60.36%)\n",
            "Performance on train2_set: Average loss: 0.6307, Accuracy: 11954/20000 (59.77%)\n",
            "Performance on test_set: Average loss: 0.7361, Accuracy: 11595/20000 (57.98%)\n",
            "Using penalty multiplier 737.6098424745011\n",
            "Performance on train1_set: Average loss: 0.6356, Accuracy: 12191/20000 (60.95%)\n",
            "Performance on train2_set: Average loss: 0.6291, Accuracy: 12000/20000 (60.00%)\n",
            "Performance on test_set: Average loss: 0.7336, Accuracy: 11608/20000 (58.04%)\n",
            "Using penalty multiplier 756.7368435045273\n",
            "Performance on train1_set: Average loss: 0.6323, Accuracy: 12184/20000 (60.92%)\n",
            "Performance on train2_set: Average loss: 0.6233, Accuracy: 12065/20000 (60.33%)\n",
            "Performance on test_set: Average loss: 0.7517, Accuracy: 11454/20000 (57.27%)\n",
            "Using penalty multiplier 776.0468820533241\n",
            "Performance on train1_set: Average loss: 0.6478, Accuracy: 12001/20000 (60.01%)\n",
            "Performance on train2_set: Average loss: 0.6474, Accuracy: 11726/20000 (58.63%)\n",
            "Performance on test_set: Average loss: 0.7056, Accuracy: 12014/20000 (60.07%)\n",
            "Using penalty multiplier 795.5388086625085\n",
            "Performance on train1_set: Average loss: 0.6445, Accuracy: 12092/20000 (60.46%)\n",
            "Performance on train2_set: Average loss: 0.6439, Accuracy: 11816/20000 (59.08%)\n",
            "Performance on test_set: Average loss: 0.7025, Accuracy: 11992/20000 (59.96%)\n",
            "Using penalty multiplier 815.2114987491829\n",
            "Performance on train1_set: Average loss: 0.6390, Accuracy: 12137/20000 (60.69%)\n",
            "Performance on train2_set: Average loss: 0.6345, Accuracy: 11908/20000 (59.54%)\n",
            "Performance on test_set: Average loss: 0.7275, Accuracy: 11760/20000 (58.80%)\n",
            "Using penalty multiplier 835.063851697083\n",
            "Performance on train1_set: Average loss: 0.6303, Accuracy: 12271/20000 (61.35%)\n",
            "Performance on train2_set: Average loss: 0.6217, Accuracy: 12068/20000 (60.34%)\n",
            "Performance on test_set: Average loss: 0.7494, Accuracy: 11534/20000 (57.67%)\n",
            "Using penalty multiplier 855.0947899940655\n",
            "Performance on train1_set: Average loss: 0.6314, Accuracy: 12115/20000 (60.58%)\n",
            "Performance on train2_set: Average loss: 0.6209, Accuracy: 11992/20000 (59.96%)\n",
            "Performance on test_set: Average loss: 0.7664, Accuracy: 11474/20000 (57.37%)\n",
            "Using penalty multiplier 875.3032584129203\n",
            "Performance on train1_set: Average loss: 0.6412, Accuracy: 12104/20000 (60.52%)\n",
            "Performance on train2_set: Average loss: 0.6388, Accuracy: 11819/20000 (59.09%)\n",
            "Performance on test_set: Average loss: 0.7150, Accuracy: 11933/20000 (59.66%)\n",
            "Using penalty multiplier 895.6882232327338\n",
            "Performance on train1_set: Average loss: 0.6432, Accuracy: 12089/20000 (60.45%)\n",
            "Performance on train2_set: Average loss: 0.6422, Accuracy: 11777/20000 (58.88%)\n",
            "Performance on test_set: Average loss: 0.7090, Accuracy: 11987/20000 (59.94%)\n",
            "Using penalty multiplier 916.2486714982427\n",
            "Performance on train1_set: Average loss: 0.6338, Accuracy: 12237/20000 (61.19%)\n",
            "Performance on train2_set: Average loss: 0.6288, Accuracy: 12013/20000 (60.06%)\n",
            "Performance on test_set: Average loss: 0.7286, Accuracy: 11777/20000 (58.88%)\n",
            "Using penalty multiplier 936.9836103148119\n",
            "Performance on train1_set: Average loss: 0.6256, Accuracy: 12363/20000 (61.81%)\n",
            "Performance on train2_set: Average loss: 0.6162, Accuracy: 12194/20000 (60.97%)\n",
            "Performance on test_set: Average loss: 0.7529, Accuracy: 11470/20000 (57.35%)\n",
            "Using penalty multiplier 957.8920661768511\n",
            "Performance on train1_set: Average loss: 0.6215, Accuracy: 12526/20000 (62.63%)\n",
            "Performance on train2_set: Average loss: 0.6124, Accuracy: 12377/20000 (61.88%)\n",
            "Performance on test_set: Average loss: 0.7468, Accuracy: 11435/20000 (57.17%)\n",
            "Using penalty multiplier 978.9730843276457\n",
            "Performance on train1_set: Average loss: 0.6321, Accuracy: 12386/20000 (61.93%)\n",
            "Performance on train2_set: Average loss: 0.6281, Accuracy: 12167/20000 (60.84%)\n",
            "Performance on test_set: Average loss: 0.7222, Accuracy: 11709/20000 (58.55%)\n",
            "Using penalty multiplier 1000.2257281487254\n",
            "Performance on train1_set: Average loss: 0.6273, Accuracy: 12506/20000 (62.53%)\n",
            "Performance on train2_set: Average loss: 0.6213, Accuracy: 12317/20000 (61.59%)\n",
            "Performance on test_set: Average loss: 0.7323, Accuracy: 11579/20000 (57.90%)\n",
            "Using penalty multiplier 1021.6490785770319\n",
            "Performance on train1_set: Average loss: 0.6292, Accuracy: 12409/20000 (62.05%)\n",
            "Performance on train2_set: Average loss: 0.6228, Accuracy: 12195/20000 (60.98%)\n",
            "Performance on test_set: Average loss: 0.7357, Accuracy: 11639/20000 (58.20%)\n",
            "Using penalty multiplier 1043.2422335482668\n",
            "Performance on train1_set: Average loss: 0.6464, Accuracy: 12191/20000 (60.95%)\n",
            "Performance on train2_set: Average loss: 0.6483, Accuracy: 11993/20000 (59.97%)\n",
            "Performance on test_set: Average loss: 0.6883, Accuracy: 11967/20000 (59.84%)\n",
            "Using penalty multiplier 1065.0043074649209\n",
            "Performance on train1_set: Average loss: 0.6383, Accuracy: 12253/20000 (61.27%)\n",
            "Performance on train2_set: Average loss: 0.6355, Accuracy: 11989/20000 (59.95%)\n",
            "Performance on test_set: Average loss: 0.7192, Accuracy: 11836/20000 (59.18%)\n",
            "Using penalty multiplier 1086.934430687584\n",
            "Performance on train1_set: Average loss: 0.6285, Accuracy: 12353/20000 (61.77%)\n",
            "Performance on train2_set: Average loss: 0.6198, Accuracy: 12200/20000 (61.00%)\n",
            "Performance on test_set: Average loss: 0.7507, Accuracy: 11555/20000 (57.77%)\n",
            "Using penalty multiplier 1109.0317490482346\n",
            "Performance on train1_set: Average loss: 0.6320, Accuracy: 12333/20000 (61.66%)\n",
            "Performance on train2_set: Average loss: 0.6260, Accuracy: 12143/20000 (60.72%)\n",
            "Performance on test_set: Average loss: 0.7321, Accuracy: 11675/20000 (58.38%)\n",
            "Using penalty multiplier 1131.2954233842977\n",
            "Performance on train1_set: Average loss: 0.6303, Accuracy: 12370/20000 (61.85%)\n",
            "Performance on train2_set: Average loss: 0.6237, Accuracy: 12175/20000 (60.88%)\n",
            "Performance on test_set: Average loss: 0.7338, Accuracy: 11662/20000 (58.31%)\n",
            "Using penalty multiplier 1153.724629092333\n",
            "Performance on train1_set: Average loss: 0.6379, Accuracy: 12210/20000 (61.05%)\n",
            "Performance on train2_set: Average loss: 0.6339, Accuracy: 11965/20000 (59.83%)\n",
            "Performance on test_set: Average loss: 0.7268, Accuracy: 11816/20000 (59.08%)\n",
            "Using penalty multiplier 1176.3185557003035\n",
            "Performance on train1_set: Average loss: 0.6309, Accuracy: 12463/20000 (62.31%)\n",
            "Performance on train2_set: Average loss: 0.6263, Accuracy: 12277/20000 (61.38%)\n",
            "Performance on test_set: Average loss: 0.7190, Accuracy: 11658/20000 (58.29%)\n",
            "Using penalty multiplier 1199.0764064574269\n",
            "Performance on train1_set: Average loss: 0.6300, Accuracy: 12465/20000 (62.33%)\n",
            "Performance on train2_set: Average loss: 0.6246, Accuracy: 12277/20000 (61.38%)\n",
            "Performance on test_set: Average loss: 0.7264, Accuracy: 11655/20000 (58.27%)\n",
            "Using penalty multiplier 1221.997397940695\n",
            "Performance on train1_set: Average loss: 0.6272, Accuracy: 12473/20000 (62.37%)\n",
            "Performance on train2_set: Average loss: 0.6203, Accuracy: 12301/20000 (61.51%)\n",
            "Performance on test_set: Average loss: 0.7353, Accuracy: 11645/20000 (58.23%)\n",
            "Using penalty multiplier 1245.0807596771863\n",
            "Performance on train1_set: Average loss: 0.6301, Accuracy: 12448/20000 (62.24%)\n",
            "Performance on train2_set: Average loss: 0.6247, Accuracy: 12253/20000 (61.27%)\n",
            "Performance on test_set: Average loss: 0.7296, Accuracy: 11703/20000 (58.52%)\n",
            "Using penalty multiplier 1268.3257337813668\n",
            "Performance on train1_set: Average loss: 0.6339, Accuracy: 12386/20000 (61.93%)\n",
            "Performance on train2_set: Average loss: 0.6304, Accuracy: 12179/20000 (60.90%)\n",
            "Performance on test_set: Average loss: 0.7196, Accuracy: 11796/20000 (58.98%)\n",
            "Using penalty multiplier 1291.7315746066158\n",
            "Performance on train1_set: Average loss: 0.6330, Accuracy: 12432/20000 (62.16%)\n",
            "Performance on train2_set: Average loss: 0.6295, Accuracy: 12237/20000 (61.19%)\n",
            "Performance on test_set: Average loss: 0.7187, Accuracy: 11762/20000 (58.81%)\n",
            "Using penalty multiplier 1315.2975484102626\n",
            "Performance on train1_set: Average loss: 0.6294, Accuracy: 12510/20000 (62.55%)\n",
            "Performance on train2_set: Average loss: 0.6244, Accuracy: 12306/20000 (61.53%)\n",
            "Performance on test_set: Average loss: 0.7246, Accuracy: 11644/20000 (58.22%)\n",
            "Using penalty multiplier 1339.022933031465\n",
            "Performance on train1_set: Average loss: 0.6220, Accuracy: 12632/20000 (63.16%)\n",
            "Performance on train2_set: Average loss: 0.6145, Accuracy: 12522/20000 (62.61%)\n",
            "Performance on test_set: Average loss: 0.7318, Accuracy: 11443/20000 (57.22%)\n",
            "Using penalty multiplier 1362.9070175812985\n",
            "Performance on train1_set: Average loss: 0.6354, Accuracy: 12326/20000 (61.63%)\n",
            "Performance on train2_set: Average loss: 0.6319, Accuracy: 12090/20000 (60.45%)\n",
            "Performance on test_set: Average loss: 0.7189, Accuracy: 11851/20000 (59.26%)\n",
            "Using penalty multiplier 1386.9491021444653\n",
            "Performance on train1_set: Average loss: 0.6441, Accuracy: 12311/20000 (61.55%)\n",
            "Performance on train2_set: Average loss: 0.6449, Accuracy: 12149/20000 (60.74%)\n",
            "Performance on test_set: Average loss: 0.6894, Accuracy: 11849/20000 (59.24%)\n",
            "Using penalty multiplier 1411.1484974920631\n",
            "Performance on train1_set: Average loss: 0.6442, Accuracy: 12321/20000 (61.60%)\n",
            "Performance on train2_set: Average loss: 0.6450, Accuracy: 12167/20000 (60.84%)\n",
            "Performance on test_set: Average loss: 0.6921, Accuracy: 11775/20000 (58.88%)\n",
            "Using penalty multiplier 1435.504524804891\n",
            "Performance on train1_set: Average loss: 0.6291, Accuracy: 12582/20000 (62.91%)\n",
            "Performance on train2_set: Average loss: 0.6243, Accuracy: 12472/20000 (62.36%)\n",
            "Performance on test_set: Average loss: 0.7186, Accuracy: 11520/20000 (57.60%)\n",
            "Using penalty multiplier 1460.0165154067959\n",
            "Performance on train1_set: Average loss: 0.6292, Accuracy: 12419/20000 (62.09%)\n",
            "Performance on train2_set: Average loss: 0.6223, Accuracy: 12233/20000 (61.16%)\n",
            "Performance on test_set: Average loss: 0.7382, Accuracy: 11708/20000 (58.54%)\n",
            "Using penalty multiplier 1484.6838105075944\n",
            "Performance on train1_set: Average loss: 0.6287, Accuracy: 12464/20000 (62.32%)\n",
            "Performance on train2_set: Average loss: 0.6230, Accuracy: 12304/20000 (61.52%)\n",
            "Performance on test_set: Average loss: 0.7270, Accuracy: 11732/20000 (58.66%)\n",
            "Using penalty multiplier 1509.5057609551284\n",
            "Performance on train1_set: Average loss: 0.6273, Accuracy: 12478/20000 (62.39%)\n",
            "Performance on train2_set: Average loss: 0.6208, Accuracy: 12289/20000 (61.45%)\n",
            "Performance on test_set: Average loss: 0.7344, Accuracy: 11691/20000 (58.45%)\n",
            "Using penalty multiplier 1534.481726996039\n",
            "Performance on train1_set: Average loss: 0.6238, Accuracy: 12599/20000 (62.99%)\n",
            "Performance on train2_set: Average loss: 0.6164, Accuracy: 12423/20000 (62.12%)\n",
            "Performance on test_set: Average loss: 0.7365, Accuracy: 11574/20000 (57.87%)\n",
            "Using penalty multiplier 1559.6110780448687\n",
            "Performance on train1_set: Average loss: 0.6324, Accuracy: 12504/20000 (62.52%)\n",
            "Performance on train2_set: Average loss: 0.6297, Accuracy: 12349/20000 (61.74%)\n",
            "Performance on test_set: Average loss: 0.7108, Accuracy: 11725/20000 (58.62%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0cabf1676604493783d6804fa4aaf8ee",
            "b1ba6dfa78b24772b1952742c7cd39df",
            "939f17ffa19b46f8b5eca9c061c78e03",
            "520a2f94594a4e1da3d896e361c61740",
            "869ab65ffc964772b4d666186b8b8863",
            "342ee64140624cb1b0f3cdfb864bfabb",
            "227e718fec004e3b940a322d609a112b",
            "a79f5f229f994d40ba7a29202ced4bcb"
          ]
        },
        "id": "o3wSBldZV7Du",
        "outputId": "324f5059-01cf-4c8b-ab99-2d55ece0d248"
      },
      "source": [
        "args.cges = True\n",
        "\n",
        "train_and_test_erm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:ag5lskhk) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 30348<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cabf1676604493783d6804fa4aaf8ee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.53MB of 0.53MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210915_130025-ag5lskhk/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210915_130025-ag5lskhk/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">apricot-oath-25</strong>: <a href=\"https://wandb.ai/arjunashok/irm-notebook/runs/ag5lskhk\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook/runs/ag5lskhk</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "...Successfully finished last run (ID:ag5lskhk). Initializing new run:<br/><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.12.1<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">legendary-frost-26</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/arjunashok/irm-notebook\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/arjunashok/irm-notebook/runs/m9ymiv37\" target=\"_blank\">https://wandb.ai/arjunashok/irm-notebook/runs/m9ymiv37</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210915_130113-m9ymiv37</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colored MNIST dataset already exists\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colored MNIST dataset already exists\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e90267c5bef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_and_test_erm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-4da0c70b0561>\u001b[0m in \u001b[0;36mtrain_and_test_erm\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     batch_size=1000, shuffle=True, **kwargs)\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unknown error\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    }
  ]
}